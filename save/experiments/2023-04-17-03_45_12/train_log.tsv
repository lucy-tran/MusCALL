Epoch	train_loss	val_loss	metric	epoch_time	learing_rate	time_stamp
1	2.0826	2.10079	13.75	127.09s	4.52254e-05	2023-04-17 03:47:22
2	1.98507	2.10089	12.5	124.363s	3.27254e-05	2023-04-17 03:49:28
3	1.91819	2.10472	15	126.346s	1.72746e-05	2023-04-17 03:51:36
4	1.85608	2.13243	12.5	125.294s	4.77458e-06	2023-04-17 03:53:45
5	1.85097	2.11866	12.5	123.302s	0	2023-04-17 03:55:50
6	1.86556	2.08956	15	126.126s	4.77458e-06	2023-04-17 03:57:58
7	1.85683	2.13767	15	122.325s	1.72746e-05	2023-04-17 04:00:02
8	1.85936	2.13597	12.5	126.993s	3.27254e-05	2023-04-17 04:02:11
9	1.85137	2.22812	10	124.781s	4.52254e-05	2023-04-17 04:04:18
10	1.86957	2.11771	11.25	130.59s	5e-05	2023-04-17 04:06:30
11	1.85813	2.12502	10	130.323s	4.52254e-05	2023-04-17 04:08:42
12	1.80019	2.1473	12.5	127.204s	3.27254e-05	2023-04-17 04:10:51
13	1.76598	2.14099	15	126.182s	1.72746e-05	2023-04-17 04:12:59
14	1.73925	2.182	12.5	123.726s	4.77458e-06	2023-04-17 04:15:05
15	1.70451	2.16532	13.75	128.209s	0	2023-04-17 04:17:15
16	1.661	2.20267	12.5	126.458s	4.77458e-06	2023-04-17 04:19:23
17	1.67388	2.21775	13.75	125.018s	1.72746e-05	2023-04-17 04:21:30
18	1.73419	2.14716	17.5	125.521s	3.27254e-05	2023-04-17 04:23:37
19	1.70715	2.24482	12.5	129.684s	4.52254e-05	2023-04-17 04:25:50
20	1.73075	2.12891	12.5	120.867s	5e-05	2023-04-17 04:27:53
21	1.71539	2.21248	11.25	128.766s	4.52254e-05	2023-04-17 04:30:04
22	1.66291	2.21702	16.25	122.289s	3.27254e-05	2023-04-17 04:32:08
23	1.63794	2.16443	12.5	125.613s	1.72746e-05	2023-04-17 04:34:15
24	1.57417	2.18784	15	124.99s	4.77458e-06	2023-04-17 04:36:22
25	1.54856	2.21023	16.25	124.564s	0	2023-04-17 04:38:28
26	1.54481	2.22395	15	124.621s	4.77458e-06	2023-04-17 04:40:35
27	1.51753	2.233	12.5	125.532s	1.72746e-05	2023-04-17 04:42:43
28	1.59575	2.25862	17.5	124.31s	3.27254e-05	2023-04-17 04:44:49
